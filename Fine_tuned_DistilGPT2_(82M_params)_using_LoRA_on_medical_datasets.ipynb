{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2Hm7vF6PYM5V1Gg0qJQ9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b630c3565c84a06a4e4241182b130ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87e08b72c8134ad1a122f6a3c42b3c22",
              "IPY_MODEL_9701d14c5f2c4ac69f348a1b3492fc21",
              "IPY_MODEL_50f10cc84b7b460db21487b50cdb1d28"
            ],
            "layout": "IPY_MODEL_2b1025ed070a47b997c6950a0cbf1fd8"
          }
        },
        "87e08b72c8134ad1a122f6a3c42b3c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9099b4e2e6984c6c8611fda072a5f4aa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d7dbaf627a3f4021a7d487213a0a8bf6",
            "value": "Map:‚Äá100%"
          }
        },
        "9701d14c5f2c4ac69f348a1b3492fc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc0cc3e14394b95b6f91eac224eca0c",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_834f58bceeb6425dab110a058e4715ee",
            "value": 12
          }
        },
        "50f10cc84b7b460db21487b50cdb1d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7e73642e8d4e4380b5c98a86df5c64",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c1e69407036648b0bedbba7f1720571d",
            "value": "‚Äá12/12‚Äá[00:00&lt;00:00,‚Äá127.39‚Äáexamples/s]"
          }
        },
        "2b1025ed070a47b997c6950a0cbf1fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9099b4e2e6984c6c8611fda072a5f4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7dbaf627a3f4021a7d487213a0a8bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fc0cc3e14394b95b6f91eac224eca0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834f58bceeb6425dab110a058e4715ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f7e73642e8d4e4380b5c98a86df5c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e69407036648b0bedbba7f1720571d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shadab007-byte/Fine-tuned-DistilGPT2-82M-params-using-LoRA-on-medical-datasets/blob/main/Fine_tuned_DistilGPT2_(82M_params)_using_LoRA_on_medical_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnqLqwMIb7IV",
        "outputId": "81c66530-fbb2-404d-97ec-a94d92918c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing dependencies...\n"
          ]
        }
      ],
      "source": [
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install -q transformers peft datasets gradio accelerate PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import Dataset\n",
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import io\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üî• GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWCqo-9icBUS",
        "outputId": "fe74ee42-e248-4c7d-9644-d51b219ee01a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully!\n",
            "üî• GPU Available: True\n",
            "   GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Extract text from uploaded PDF file\"\"\"\n",
        "    try:\n",
        "        if pdf_file is None:\n",
        "            return None\n",
        "\n",
        "        # Ensure bytes\n",
        "        pdf_bytes = pdf_file.read() if hasattr(pdf_file, \"read\") else pdf_file\n",
        "\n",
        "        # Read from bytes\n",
        "        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_bytes))\n",
        "\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "1pT3fXChcO1Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DATA = [\n",
        "    {\n",
        "        \"report\": \"Patient presents with acute bronchitis. Auscultation reveals bilateral wheezing and rhonchi. Prescribed albuterol inhaler 90mcg, 2 puffs q4-6h PRN and azithromycin 250mg daily for 5 days.\",\n",
        "        \"summary\": \"You have a chest infection causing wheezing. Use the inhaler (2 puffs every 4-6 hours when needed) and take antibiotics once daily for 5 days.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Laboratory results indicate elevated HbA1c at 8.2%, fasting glucose 165mg/dL. Diagnosis: Type 2 Diabetes Mellitus. Initiated metformin 500mg BID, advised carbohydrate-controlled diet and 30min aerobic exercise 5x/week.\",\n",
        "        \"summary\": \"Your blood sugar levels are high, indicating diabetes. Take metformin twice daily, reduce carbs in your diet, and exercise 30 minutes five times a week.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"MRI findings: L4-L5 disc herniation with posterior protrusion causing mild neural foraminal stenosis. Recommend physical therapy, NSAIDs for pain management, and consideration of epidural steroid injection if symptoms persist.\",\n",
        "        \"summary\": \"Your MRI shows a herniated disc in your lower back pressing on nerves. Start physical therapy and take anti-inflammatory medication. If pain continues, we may recommend an injection.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Echocardiogram reveals ejection fraction of 45%, mild left ventricular hypertrophy. Diagnosis: Heart failure with reduced ejection fraction. Prescribed lisinopril 10mg daily, carvedilol 3.125mg BID, furosemide 20mg daily.\",\n",
        "        \"summary\": \"Your heart isn't pumping as efficiently as it should. Take three medications daily as prescribed: one for blood pressure, one for heart rate, and one water pill.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Dermatological examination shows multiple nevi with irregular borders. Excisional biopsy of 6mm lesion on left shoulder performed. Pathology pending. Follow-up in 2 weeks for results and suture removal.\",\n",
        "        \"summary\": \"We removed a suspicious mole from your shoulder for testing. Come back in 2 weeks to get the stitches removed and discuss the results.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Complete blood count reveals hemoglobin 9.2g/dL, MCV 72fL, ferritin 8ng/mL. Diagnosis: Iron deficiency anemia. Prescribed ferrous sulfate 325mg TID with vitamin C, avoid taking with dairy products.\",\n",
        "        \"summary\": \"You have low iron causing anemia. Take iron supplements three times daily with vitamin C, but not with milk or dairy products.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Sleep study demonstrates AHI of 32 events/hour, oxygen desaturation to 82%. Diagnosis: Severe obstructive sleep apnea. CPAP therapy initiated at 10cm H2O, follow-up titration study in 6 weeks.\",\n",
        "        \"summary\": \"Your sleep test shows you stop breathing frequently during sleep. You'll use a CPAP machine at night to help you breathe. We'll adjust settings in 6 weeks.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Thyroid function tests: TSH 12.4 mIU/L, Free T4 0.6ng/dL. Diagnosis: Hypothyroidism. Started levothyroxine 50mcg daily, take on empty stomach 30min before breakfast. Recheck labs in 8 weeks.\",\n",
        "        \"summary\": \"Your thyroid is underactive. Take thyroid medication every morning on an empty stomach, 30 minutes before eating. We'll retest in 8 weeks.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Chest X-ray shows bilateral infiltrates, fever 101.5¬∞F, SpO2 89% on room air. Diagnosis: Community-acquired pneumonia. Admitted for IV ceftriaxone 1g daily and azithromycin 500mg daily, supplemental oxygen via nasal cannula.\",\n",
        "        \"summary\": \"You have pneumonia in both lungs. We're admitting you to the hospital for IV antibiotics and oxygen support until you improve.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Colonoscopy revealed 8mm polyp at hepatic flexure, removed via snare polypectomy. Pathology: tubular adenoma with low-grade dysplasia. Recommend repeat colonoscopy in 3 years.\",\n",
        "        \"summary\": \"We found and removed a benign polyp during your colonoscopy. It wasn't cancerous, but come back for another screening in 3 years.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Patient History: 55-year-old male with hypertension (diagnosed 2018), type 2 diabetes (2019), and hyperlipidemia. Previous MI in 2020, underwent PCI with stent placement. Current medications: aspirin 81mg, atorvastatin 40mg, metformin 1000mg BID, lisinopril 20mg. Recent labs show HbA1c 7.1%, LDL 95mg/dL, BP 128/82.\",\n",
        "        \"summary\": \"This 55-year-old man has high blood pressure, diabetes, and high cholesterol. He had a heart attack in 2020 and got a stent. He takes 4 daily medications. His recent tests show good control of diabetes and cholesterol, with stable blood pressure.\"\n",
        "    },\n",
        "    {\n",
        "        \"report\": \"Medical History Summary: 42F with recurrent UTIs (3 episodes this year), IBS diagnosed 2015, seasonal allergies. Surgical history includes C-section 2010 and appendectomy 2008. Family history significant for breast cancer (mother, age 58). Takes daily probiotic, cetirizine 10mg PRN.\",\n",
        "        \"summary\": \"This 42-year-old woman has repeated bladder infections, irritable bowel syndrome, and seasonal allergies. She's had two previous surgeries. Her mother had breast cancer, so she should discuss screening. She takes probiotics daily and allergy medicine as needed.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(TRAINING_DATA)} training examples (including patient histories)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRutZKqwcTg4",
        "outputId": "83bc0e6c-4ee7-4f8e-d0f7-04e441feec72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 12 training examples (including patient histories)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset():\n",
        "    \"\"\"Format data for training\"\"\"\n",
        "    formatted_data = []\n",
        "    for item in TRAINING_DATA:\n",
        "        text = f\"### Medical Report:\\n{item['report']}\\n\\n### Patient Summary:\\n{item['summary']}<|endoftext|>\"\n",
        "        formatted_data.append({\"text\": text})\n",
        "    return Dataset.from_list(formatted_data)\n",
        "\n",
        "dataset = prepare_dataset()\n",
        "print(f\"‚úÖ Dataset prepared: {len(dataset)} examples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DnrcoYxcXca",
        "outputId": "d22cda82-bf47-4014-df36-2b2d327dc623"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset prepared: 12 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilgpt2\"\n",
        "\n",
        "print(f\"üîÑ Loading {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model loaded on: {model.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEw2og7WcbN_",
        "outputId": "a62fad65-82d3-4a2b-ce5b-ece9e99c4233"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading distilgpt2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(\"\\nüìä Trainable Parameters:\")\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDBC9ynEcj6M",
        "outputId": "1b799a51-2f35-4254-fef0-52a94234d1a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Trainable Parameters:\n",
            "trainable params: 294,912 || all params: 82,207,488 || trainable%: 0.3587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=512,  # Increased for longer patient histories\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names\n",
        ")\n",
        "print(f\"‚úÖ Dataset tokenized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6b630c3565c84a06a4e4241182b130ce",
            "87e08b72c8134ad1a122f6a3c42b3c22",
            "9701d14c5f2c4ac69f348a1b3492fc21",
            "50f10cc84b7b460db21487b50cdb1d28",
            "2b1025ed070a47b997c6950a0cbf1fd8",
            "9099b4e2e6984c6c8611fda072a5f4aa",
            "d7dbaf627a3f4021a7d487213a0a8bf6",
            "3fc0cc3e14394b95b6f91eac224eca0c",
            "834f58bceeb6425dab110a058e4715ee",
            "4f7e73642e8d4e4380b5c98a86df5c64",
            "c1e69407036648b0bedbba7f1720571d"
          ]
        },
        "id": "QPiPrROlcqki",
        "outputId": "4b2a4f11-54e3-452d-aa55-3340ac0efb71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b630c3565c84a06a4e4241182b130ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset tokenized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./medisummarize\",\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=2,\n",
        "    learning_rate=3e-4,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\"*60)\n",
        "trainer.train()\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JyfbH2CGcuxj",
        "outputId": "e921eed3-3520-4bad-da5e-8c68754736c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting training...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:28, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.542500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>4.265100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>4.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.958600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.729800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.559700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.474400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>3.285800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.175700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.228700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>3.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.086400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.976900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.954700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.943400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.854200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.845100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.832800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.806000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.776600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.732500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.736200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.770300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.710400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.710400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.709600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.686400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.723300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "‚úÖ Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Extract text from uploaded PDF file\"\"\"\n",
        "    try:\n",
        "        if pdf_file is None:\n",
        "            return None\n",
        "\n",
        "        # ‚úÖ Handle various input types\n",
        "        if hasattr(pdf_file, \"read\"):  # e.g., file-like object from Gradio/Streamlit\n",
        "            pdf_bytes = pdf_file.read()\n",
        "        elif isinstance(pdf_file, (bytes, bytearray)):\n",
        "            pdf_bytes = pdf_file\n",
        "        elif isinstance(pdf_file, str):  # path string\n",
        "            with open(pdf_file, \"rb\") as f:\n",
        "                pdf_bytes = f.read()\n",
        "        else:\n",
        "            return \"Error extracting PDF: Unsupported file type.\"\n",
        "\n",
        "        # ‚úÖ Read using PyPDF2\n",
        "        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_bytes))\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "\n",
        "def generate_summary(medical_report):\n",
        "    \"\"\"Generate patient-friendly summary\"\"\"\n",
        "    if not medical_report or not medical_report.strip():\n",
        "        return \"‚ö†Ô∏è Please enter a medical report or upload a PDF.\"\n",
        "\n",
        "    # Truncate if too long\n",
        "    if len(medical_report) > 1500:\n",
        "        medical_report = medical_report[:1500] + \"...\"\n",
        "\n",
        "    prompt = f\"### Medical Report:\\n{medical_report}\\n\\n### Patient Summary:\\n\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            repetition_penalty=1.2\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    if \"### Patient Summary:\" in generated_text:\n",
        "        summary = generated_text.split(\"### Patient Summary:\")[1].strip()\n",
        "        return summary\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "def process_pdf_and_summarize(pdf_file):\n",
        "    \"\"\"Extract text from PDF and generate summary\"\"\"\n",
        "    if pdf_file is None:\n",
        "        return \"\", \"‚ö†Ô∏è Please upload a PDF file.\"\n",
        "\n",
        "    extracted_text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "    if isinstance(extracted_text, str) and extracted_text.startswith(\"Error\"):\n",
        "        return extracted_text, \"\"\n",
        "\n",
        "    summary = generate_summary(extracted_text)\n",
        "\n",
        "    return extracted_text, summary\n",
        "\n",
        "\n",
        "print(\"‚úÖ Inference functions ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gvlXfmTc-Rg",
        "outputId": "78091cfb-0657-4728-8723-e376665bdf6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Inference functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüß™ Testing model...\")\n",
        "test_report = \"Blood pressure 165/95, BMI 31. Diagnosis: Stage 2 Hypertension. Started lisinopril 10mg daily, DASH diet advised.\"\n",
        "test_summary = generate_summary(test_report)\n",
        "print(f\"‚ú® Test Summary: {test_summary[:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XofDdlm_dEmX",
        "outputId": "446b4c95-f9aa-4440-9855-2ae6f18db731"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testing model...\n",
            "‚ú® Test Summary: Your blood pressure 165 pounds and recommend a weekly vitamin B12-6 supplement to your doctor every ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_REPORTS = {\n",
        "    \"Fracture (X-ray)\": \"X-ray imaging shows fracture of distal radius with dorsal angulation. Closed reduction performed, short arm cast applied. Prescribed ibuprofen 400mg TID for pain, follow-up in 1 week for repeat imaging.\",\n",
        "\n",
        "    \"UTI (Lab Test)\": \"Urinalysis positive for nitrites and leukocyte esterase. Diagnosis: Urinary tract infection. Prescribed nitrofurantoin 100mg BID for 7 days. Increase fluid intake to 2-3L daily.\",\n",
        "\n",
        "    \"COPD (Lung Function)\": \"Spirometry reveals FEV1/FVC ratio of 0.65, FEV1 55% predicted. Diagnosis: Moderate COPD. Initiated tiotropium inhaler 18mcg daily, albuterol rescue inhaler as needed.\",\n",
        "\n",
        "    \"Appendicitis (Emergency)\": \"CT scan shows acute appendicitis with periappendiceal stranding. WBC 15,000. Emergency appendectomy scheduled. NPO status, IV antibiotics initiated.\",\n",
        "\n",
        "    \"Patient History\": \"Patient History: 62-year-old female with long-standing rheumatoid arthritis (2005), osteoporosis, GERD. Takes methotrexate 15mg weekly, folic acid, omeprazole 20mg daily, calcium+vitamin D. Recent DEXA scan shows T-score -2.8 at lumbar spine. No fractures. Referred to rheumatology for biologic therapy consideration.\"\n",
        "}"
      ],
      "metadata": {
        "id": "nijAxP7wdOtk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"MediSummarize\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üè• MediSummarize: AI Medical Report Simplifier\n",
        "    ### LoRA Fine-tuned LLM for Patient-Friendly Medical Summaries\n",
        "\n",
        "    Upload PDF medical reports or paste text to get easy-to-understand summaries.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"üìÑ PDF Upload\"):\n",
        "        gr.Markdown(\"### Upload Medical Report PDF\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                pdf_input = gr.File(\n",
        "                    label=\"Upload PDF Medical Report\",\n",
        "                    file_types=[\".pdf\"]\n",
        "                )\n",
        "                pdf_btn = gr.Button(\"üîç Extract & Summarize\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column():\n",
        "                extracted_text = gr.Textbox(\n",
        "                    label=\"üìã Extracted Text\",\n",
        "                    lines=8,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        summary_from_pdf = gr.Textbox(\n",
        "            label=\"‚ú® Patient-Friendly Summary\",\n",
        "            lines=6,\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        pdf_btn.click(\n",
        "            process_pdf_and_summarize,\n",
        "            inputs=pdf_input,\n",
        "            outputs=[extracted_text, summary_from_pdf]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"‚úçÔ∏è Text Input\"):\n",
        "        gr.Markdown(\"### Enter or Paste Medical Report\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                text_input = gr.Textbox(\n",
        "                    label=\"üìÑ Medical Report / Patient History\",\n",
        "                    placeholder=\"Paste medical report here...\",\n",
        "                    lines=10\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    summarize_btn = gr.Button(\"‚ú® Generate Summary\", variant=\"primary\", size=\"lg\")\n",
        "                    clear_btn = gr.Button(\"üóëÔ∏è Clear\", size=\"lg\")\n",
        "\n",
        "                gr.Markdown(\"**üìù Try Sample Reports:**\")\n",
        "                sample_dropdown = gr.Dropdown(\n",
        "                    choices=list(SAMPLE_REPORTS.keys()),\n",
        "                    label=\"Select Sample\",\n",
        "                    value=None\n",
        "                )\n",
        "                load_sample_btn = gr.Button(\"Load Sample\", size=\"sm\")\n",
        "\n",
        "            with gr.Column():\n",
        "                summary_output = gr.Textbox(\n",
        "                    label=\"üí¨ Patient-Friendly Summary\",\n",
        "                    lines=14,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        # Button actions\n",
        "        summarize_btn.click(generate_summary, inputs=text_input, outputs=summary_output)\n",
        "        clear_btn.click(lambda: (\"\", \"\"), outputs=[text_input, summary_output])\n",
        "\n",
        "        def load_sample(choice):\n",
        "            return SAMPLE_REPORTS.get(choice, \"\")\n",
        "\n",
        "        load_sample_btn.click(load_sample, inputs=sample_dropdown, outputs=text_input)\n",
        "\n",
        "    with gr.Tab(\"‚ÑπÔ∏è Project Info\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## üéØ About MediSummarize\n",
        "\n",
        "        An AI-powered tool that converts complex medical reports into patient-friendly language using fine-tuned Large Language Models.\n",
        "\n",
        "        ### üî¨ Technical Stack\n",
        "        - **Base Model:** DistilGPT2 (82M parameters)\n",
        "        - **Fine-tuning Method:** LoRA (Low-Rank Adaptation)\n",
        "        - **Framework:** HuggingFace Transformers + PEFT\n",
        "        - **PDF Processing:** PyPDF2\n",
        "        - **Interface:** Gradio\n",
        "        - **Training:** 15 epochs, 3e-4 learning rate\n",
        "\n",
        "        ### üìä Dataset\n",
        "        - **Size:** 12 medical report-summary pairs\n",
        "        - **Types:** Lab results, imaging reports, prescriptions, patient histories\n",
        "        - **Domains:** Cardiology, pulmonology, endocrinology, orthopedics, gastroenterology\n",
        "\n",
        "        ### ‚ú® Key Features\n",
        "        - ‚úÖ PDF medical report upload and text extraction\n",
        "        - ‚úÖ Patient history summarization\n",
        "        - ‚úÖ Multi-page document support\n",
        "        - ‚úÖ Real-time text input processing\n",
        "        - ‚úÖ Pre-loaded sample reports\n",
        "        - ‚úÖ LoRA efficient fine-tuning (trainable params: ~0.3M vs 82M)\n",
        "\n",
        "        ### üéì Skills Demonstrated\n",
        "        - Large Language Model fine-tuning\n",
        "        - Parameter-Efficient Fine-Tuning (PEFT/LoRA)\n",
        "        - Natural Language Processing\n",
        "        - PDF document processing\n",
        "        - Healthcare AI applications\n",
        "        - Model deployment with Gradio\n",
        "        - GPU-accelerated training\n",
        "\n",
        "        ### üìà Model Performance\n",
        "        - Training time: ~2-3 minutes on T4 GPU\n",
        "        - Inference time: <2 seconds per report\n",
        "        - Memory efficient: LoRA reduces trainable parameters by 99.6%\n",
        "\n",
        "        ### üöÄ Use Cases\n",
        "        - Hospital patient education\n",
        "        - Telemedicine platforms\n",
        "        - Personal health record systems\n",
        "        - Medical literacy tools\n",
        "        - Healthcare accessibility\n",
        "\n",
        "        ---\n",
        "\n",
        "        **Created as a demonstration of LLM fine-tuning capabilities**\n",
        "        \"\"\")"
      ],
      "metadata": {
        "id": "bHQjXrC5dUcI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ MediSummarize is ready!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "HiguRQjcf6C2"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}